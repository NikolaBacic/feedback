{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import transformers\n",
    "from transformers import RobertaConfig, RobertaTokenizerFast\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from param_roberta_base import param\n",
    "from param_roberta import param\n",
    "from processing_roberta import preprocess, discourse_map\n",
    "from dataset_roberta import RobertaDataset\n",
    "from model_roberta import init_roberta\n",
    "\n",
    "sys.path.append('/home/backe/projects/feedback/')\n",
    "from utils import seed_everything, moving_average, score_feedback_comp\n",
    "\n",
    "seed_everything(param['random_seed'])\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144293, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15594/15594 [04:43<00:00, 55.09it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained(param['model_name'])\n",
    "\n",
    "TRAIN_PATH = '../data/train_clean.csv'\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "print(train_df.shape)\n",
    "train_df.head()\n",
    "\n",
    "TEXT_FILES = os.listdir('../data/train')\n",
    "TEXT_FILES = [f'../data/train/{file}' for file in TEXT_FILES]\n",
    "\n",
    "text_data = dict()\n",
    "for file_path in TEXT_FILES:\n",
    "    with open(file_path, 'r') as file:\n",
    "        idx = os.path.basename(file_path).split('.txt')[0]\n",
    "        text_data[idx] = file.read()\n",
    "        \n",
    "data = preprocess(text_data, tokenizer, train_df)\n",
    "roberta_df = pd.DataFrame(data, columns=['id', 'input_ids', 'attention_mask', 'token_to_word', 'target'])\n",
    "folds_df = pd.read_csv('../data/folds.csv')\n",
    "roberta_df = roberta_df.merge(folds_df, on='id')\n",
    "roberta_df.to_csv('/DATA/backe/feedback/data/roberta_preprocessed_new.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD PREPROCESSED DATA\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(param['model_name'])\n",
    "# load saved processed data\n",
    "DATA_PATH = '/DATA/backe/feedback/data/roberta_preprocessed.csv'\n",
    "data = pd.read_csv(DATA_PATH)\n",
    "data['input_ids'] = data['input_ids'].apply(eval)\n",
    "data['attention_mask'] = data['attention_mask'].apply(eval)\n",
    "data['token_to_word'] = data['token_to_word'].apply(eval)\n",
    "data['target'] = data['target'].apply(eval)\n",
    "\n",
    "# GET DATALOADERS\n",
    "dataset = RobertaDataset(data, tokenizer, param)\n",
    "\n",
    "train_dataloader, val_dataloader = dataset.get_dataloaders(param['fold_idx'])\n",
    "\n",
    "# MODEL INITIALIZATION\n",
    "model = init_roberta(param)\n",
    "\n",
    "# VAL_DF\n",
    "TRAIN_PATH = '../data/train.csv'\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "\n",
    "fold_ids = data.loc[data['kfold'] == param['fold_idx'], 'id']\n",
    "val_df = train_df[train_df['id'].isin(fold_ids)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_polynomial_decay_schedule_with_warmup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimizer - Adam\n",
    "optimizer = AdamW(model.parameters(), lr=model.param['lr'])\n",
    "# define lr scheduler\n",
    "num_train_steps = model.param['epochs'] * len(train_dataloader)\n",
    "scheduler = get_polynomial_decay_schedule_with_warmup(optimizer,\n",
    "                                                      model.param['warmup_steps'],\n",
    "                                                      num_train_steps,\n",
    "                                                      lr_end=model.param['lr_end'],\n",
    "                                                     power=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in tqdm(train_dataloader):\n",
    "    \n",
    "    lrs.append(optimizer.param_groups[0]['lr'])\n",
    "    \n",
    "    scheduler.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(lrs).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(lrs).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(lrs).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT MOVING AVERAGE TRAIN LOSS\n",
    "ma_loss = moving_average(np.array(losses), window_size=50)\n",
    "plt.rcParams['figure.figsize'] = (20, 5)\n",
    "plt.plot(ma_loss[:])\n",
    "plt.hlines(0.4 , xmin=0, xmax=len(ma_loss[:]), colors='r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET WORD LEVEL PROBABILITIES \n",
    "\n",
    "model.eval()\n",
    "\n",
    "word_probs_all = dict()\n",
    "\n",
    "for batch in tqdm(val_dataloader):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(batch['input_ids'].cuda(),\n",
    "                       attention_mask=batch['attention_mask'].cuda())\n",
    "    \n",
    "    sample_probs = torch.softmax(output, axis=-1).cpu()\n",
    "    sample_probs = sample_probs.view(-1, param['num_labels'])\n",
    "    \n",
    "    loss_mask = batch['loss_mask'].view(-1) == 1\n",
    "\n",
    "    token_probs = sample_probs[loss_mask]\n",
    "    \n",
    "    token_to_word = batch['token_to_word'].reshape(-1)\n",
    "    token_to_word = token_to_word[loss_mask]\n",
    "    \n",
    "    num_words = token_to_word.max().item()+1\n",
    "\n",
    "    word_probs = [token_probs[token_to_word == word_id].mean(0).numpy() for word_id in range(num_words)]\n",
    "    word_probs_all[batch['id']] = np.array(word_probs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTIONS FORMATTING\n",
    "\n",
    "val_preds = []\n",
    "\n",
    "for idx in tqdm(word_probs_all.keys()):\n",
    "    \n",
    "    word_probs = word_probs_all[idx]\n",
    "    \n",
    "    preds_decoded = decode_predictions(idx, word_probs)\n",
    "    \n",
    "    val_preds += preds_decoded\n",
    "    \n",
    "preds_df = pd.DataFrame(val_preds, columns=['id', 'class', 'predictionstring'])\n",
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = '../data/train.csv'\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "train_df.head()\n",
    "\n",
    "# VALID DATAFRAME\n",
    "true_df = train_df.loc[train_df['id'].isin(preds_df['id'].unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1s = []\n",
    "\n",
    "CLASSES = preds_df['class'].unique()\n",
    "for c in CLASSES:\n",
    "    pred_df = preds_df.loc[preds_df['class']==c].copy()\n",
    "    gt_df = true_df.loc[true_df['discourse_type']==c].copy()\n",
    "    f1 = score_feedback_comp(pred_df, gt_df)\n",
    "    print(c,f1)\n",
    "    f1s.append(f1)\n",
    "print()\n",
    "print('Overall', np.mean(f1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Position 0.7157822428301562\n",
    "# Concluding Statement 0.8666420391577392\n",
    "# Claim 0.6496393267432541\n",
    "# Evidence 0.7577560806516841\n",
    "# Lead 0.8326596604688763\n",
    "# Counterclaim 0.5556544968833482\n",
    "# Rebuttal 0.5057610673135233\n",
    "\n",
    "# Overall 0.6976992734355116\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # saving\n",
    "\n",
    "# model.save_pretrained(param['save_dir'])\n",
    "# tokenizer.save_pretrained(param['save_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
