{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import transformers\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Longformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LF_DATA_PATH = '/storage/backe/feedback/data/longformer_preprocessed.csv'\n",
    "data_lf = pd.read_csv(LF_DATA_PATH)\n",
    "data_lf['input_ids'] = data_lf['input_ids'].apply(eval)\n",
    "data_lf['attention_mask'] = data_lf['attention_mask'].apply(eval)\n",
    "data_lf['token_to_word'] = data_lf['token_to_word'].apply(eval)\n",
    "data_lf['target'] = data_lf['target'].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LF_PATH_0 = '/storage/backe/feedback/longformer/longformer-0fold/'\n",
    "LF_PATH_1 = '/storage/backe/feedback/longformer/longformer-1fold/'\n",
    "LF_PATH_2 = '/storage/backe/feedback/longformer/longformer-2fold/'\n",
    "LF_PATH_3 = '/storage/backe/feedback/longformer/longformer-3fold/'\n",
    "LF_PATH_4 = '/storage/backe/feedback/longformer/longformer-4fold/'\n",
    "\n",
    "sys.path.append(LF_PATH_0)\n",
    "sys.path.append(LF_PATH_1)\n",
    "sys.path.append(LF_PATH_2)\n",
    "sys.path.append(LF_PATH_3)\n",
    "sys.path.append(LF_PATH_4)\n",
    "\n",
    "from param_longformer_0 import param as param_lf_0\n",
    "from param_longformer_1 import param as param_lf_1\n",
    "from param_longformer_2 import param as param_lf_2\n",
    "from param_longformer_3 import param as param_lf_3\n",
    "from param_longformer_4 import param as param_lf_4\n",
    "\n",
    "param_lf_0['kaggle_path'] = LF_PATH_0\n",
    "param_lf_1['kaggle_path'] = LF_PATH_1\n",
    "param_lf_2['kaggle_path'] = LF_PATH_2\n",
    "param_lf_3['kaggle_path'] = LF_PATH_3\n",
    "param_lf_4['kaggle_path'] = LF_PATH_4\n",
    "\n",
    "from transformers import LongformerConfig, LongformerTokenizerFast\n",
    "from dataset_longformer import LongformerDataset, Collate\n",
    "from model_longformer import load_longformer\n",
    "\n",
    "tokenizer_lf = LongformerTokenizerFast.from_pretrained(param_lf_0['model_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store longformer fold's predictions here\n",
    "word_probs_lf = []\n",
    "\n",
    "params_lf = [param_lf_0, param_lf_1, param_lf_2, param_lf_3, param_lf_4]\n",
    "\n",
    "for e, param_lf in enumerate(params_lf):\n",
    "        \n",
    "    collate_fn = Collate(tokenizer_lf, purpose='train')\n",
    "    dataset_lf = LongformerDataset(data_lf, param_lf, purpose='train')\n",
    "\n",
    "    _, val_dataloader_lf = dataset_lf.get_dataloaders(collate_fn, param_lf['fold_idx'])\n",
    "\n",
    "    model_lf = load_longformer(param_lf)\n",
    "    \n",
    "    word_probs_lf.append(model_lf.get_words_probabilities(val_dataloader_lf))\n",
    "    \n",
    "    print(f'{e}. finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = {**word_probs_lf[0], **word_probs_lf[1], **word_probs_lf[2], **word_probs_lf[3], **word_probs_lf[4]}\n",
    "with open('word_probs_lf.pickle', 'wb') as handle:\n",
    "    pickle.dump(z, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved processed data\n",
    "RL_DATA_PATH = '/DATA/backe/feedback/data/roberta_preprocessed.csv'\n",
    "data_rl = pd.read_csv(RL_DATA_PATH)\n",
    "data_rl['input_ids'] = data_rl['input_ids'].apply(eval)\n",
    "data_rl['attention_mask'] = data_rl['attention_mask'].apply(eval)\n",
    "data_rl['token_to_word'] = data_rl['token_to_word'].apply(eval)\n",
    "data_rl['target'] = data_rl['target'].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_PATH_0 = '/DATA/backe/feedback/roberta/roberta-0fold/'\n",
    "RF_PATH_1 = '/DATA/backe/feedback/roberta/roberta-1fold/'\n",
    "RF_PATH_2 = '/DATA/backe/feedback/roberta/roberta-2fold/'\n",
    "RF_PATH_3 = '/DATA/backe/feedback/roberta/roberta-3fold/'\n",
    "RF_PATH_4 = '/DATA/backe/feedback/roberta/roberta-4fold/'\n",
    "\n",
    "sys.path.append(RF_PATH_0)\n",
    "sys.path.append(RF_PATH_1)\n",
    "sys.path.append(RF_PATH_2)\n",
    "sys.path.append(RF_PATH_3)\n",
    "sys.path.append(RF_PATH_4)\n",
    "\n",
    "from param_roberta_0 import param as param_rl_0\n",
    "from param_roberta_1 import param as param_rl_1\n",
    "from param_roberta_2 import param as param_rl_2\n",
    "from param_roberta_3 import param as param_rl_3\n",
    "from param_roberta_4 import param as param_rl_4\n",
    "\n",
    "param_rl_0['kaggle_path'] = RF_PATH_0\n",
    "param_rl_1['kaggle_path'] = RF_PATH_1\n",
    "param_rl_2['kaggle_path'] = RF_PATH_2\n",
    "param_rl_3['kaggle_path'] = RF_PATH_3\n",
    "param_rl_4['kaggle_path'] = RF_PATH_4\n",
    "\n",
    "from transformers import RobertaConfig, RobertaTokenizerFast\n",
    "from dataset_roberta import RobertaDataset\n",
    "from model_roberta import load_roberta\n",
    "\n",
    "tokenizer_rl = RobertaTokenizerFast.from_pretrained(param_rl_0['model_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store roberta fold's predictions here\n",
    "word_probs_rl = []\n",
    "\n",
    "params_rl = [param_rl_0, param_rl_1, param_rl_2, param_rl_3, param_rl_4]\n",
    "\n",
    "for e, param_rl in enumerate(params_rl):\n",
    "        \n",
    "    dataset_rl = RobertaDataset(data_rl, tokenizer_rl, param_rl)\n",
    "\n",
    "    _, val_dataloader_rl = dataset_rl.get_dataloaders(param_rl['fold_idx'])\n",
    "\n",
    "    model_rl = load_roberta(param_rl)\n",
    "    \n",
    "    word_probs_rl.append(model_rl.get_words_probabilities(val_dataloader_rl))\n",
    "    \n",
    "    print(f'{e}. finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = {**word_probs_rl[0], **word_probs_rl[1], **word_probs_rl[2], **word_probs_rl[3], **word_probs_rl[4]}\n",
    "with open('word_probs_rl.pickle', 'wb') as handle:\n",
    "    pickle.dump(z, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Deberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved processed data\n",
    "DB_DATA_PATH = '/DATA/backe/feedback/data/deberta_preprocessed.csv'\n",
    "data_db = pd.read_csv(DB_DATA_PATH)\n",
    "data_db['input_ids'] = data_db['input_ids'].apply(eval)\n",
    "data_db['attention_mask'] = data_db['attention_mask'].apply(eval)\n",
    "data_db['token_to_word'] = data_db['token_to_word'].apply(eval)\n",
    "data_db['target'] = data_db['target'].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_PATH_0 = '/DATA/backe/feedback/deberta/deberta-0fold/'\n",
    "DB_PATH_1 = '/DATA/backe/feedback/deberta/deberta-1fold/'\n",
    "DB_PATH_2 = '/DATA/backe/feedback/deberta/deberta-2fold/'\n",
    "DB_PATH_3 = '/DATA/backe/feedback/deberta/deberta-3fold/'\n",
    "DB_PATH_4 = '/DATA/backe/feedback/deberta/deberta-4fold/'\n",
    "\n",
    "sys.path.append(DB_PATH_0)\n",
    "sys.path.append(DB_PATH_1)\n",
    "sys.path.append(DB_PATH_2)\n",
    "sys.path.append(DB_PATH_3)\n",
    "sys.path.append(DB_PATH_4)\n",
    "\n",
    "from param_deberta_0 import param as param_db_0\n",
    "from param_deberta_1 import param as param_db_1\n",
    "from param_deberta_2 import param as param_db_2\n",
    "from param_deberta_3 import param as param_db_3\n",
    "from param_deberta_4 import param as param_db_4\n",
    "\n",
    "param_db_0['kaggle_path'] = DB_PATH_0\n",
    "param_db_1['kaggle_path'] = DB_PATH_1\n",
    "param_db_2['kaggle_path'] = DB_PATH_2\n",
    "param_db_3['kaggle_path'] = DB_PATH_3\n",
    "param_db_4['kaggle_path'] = DB_PATH_4\n",
    "\n",
    "from transformers import DebertaConfig, DebertaTokenizerFast\n",
    "from dataset_deberta import DebertaDataset\n",
    "from model_deberta import load_deberta\n",
    "\n",
    "tokenizer_db = DebertaTokenizerFast.from_pretrained(param_db_0['model_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. finished!\n",
      "1. finished!\n",
      "2. finished!\n",
      "3. finished!\n",
      "4. finished!\n"
     ]
    }
   ],
   "source": [
    "# store deberta fold's predictions here\n",
    "word_probs_db = []\n",
    "\n",
    "params_db = [param_db_0, param_db_1, param_db_2, param_db_3, param_db_4]\n",
    "\n",
    "for e, param_db in enumerate(params_db):\n",
    "        \n",
    "    dataset_db = DebertaDataset(data_db, tokenizer_db, param_db)\n",
    "\n",
    "    _, val_dataloader_db = dataset_db.get_dataloaders(param_db['fold_idx'])\n",
    "\n",
    "    model_db = load_deberta(param_db)\n",
    "    \n",
    "    word_probs_db.append(model_db.get_words_probabilities(val_dataloader_db))\n",
    "    \n",
    "    print(f'{e}. finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = {**word_probs_db[0], **word_probs_db[1], **word_probs_db[2], **word_probs_db[3], **word_probs_db[4]}\n",
    "with open('word_probs_db.pickle', 'wb') as handle:\n",
    "    pickle.dump(z, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
