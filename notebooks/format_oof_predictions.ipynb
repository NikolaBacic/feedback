{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format oof predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('word_probs_lf.pickle', 'rb') as handle:\n",
    "    word_probs_lf = pickle.load(handle)\n",
    "    \n",
    "with open('word_probs_rl.pickle', 'rb') as handle:\n",
    "    word_probs_rl = pickle.load(handle)\n",
    "\n",
    "with open('word_probs_db.pickle', 'rb') as handle:\n",
    "    word_probs_db = pickle.load(handle)\n",
    "    \n",
    "word_probs_all = {}\n",
    "\n",
    "for idx in word_probs_lf.keys():\n",
    "    \n",
    "    word_probs_all[idx] = np.mean((word_probs_lf[idx], word_probs_rl[idx], word_probs_db[idx]), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizerFast\n",
    "# LOAD PREPROCESSED DATA\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-large')\n",
    "# load saved processed data\n",
    "DATA_PATH = '/storage/backe/feedback/data/roberta_preprocessed.csv'\n",
    "data = pd.read_csv(DATA_PATH)\n",
    "data['input_ids'] = data['input_ids'].apply(eval)\n",
    "data['attention_mask'] = data['attention_mask'].apply(eval)\n",
    "data['token_to_word'] = data['token_to_word'].apply(eval)\n",
    "data['target'] = data['target'].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_FILES = os.listdir('../data/train')\n",
    "TEXT_FILES = [f'../data/train/{file}' for file in TEXT_FILES]\n",
    "\n",
    "text_data = dict()\n",
    "\n",
    "for file_path in TEXT_FILES:\n",
    "    with open(file_path, 'r') as file:\n",
    "        idx = os.path.basename(file_path).split('.txt')[0]\n",
    "        text_data[idx] = file.read()\n",
    "\n",
    "# preprocessing steps\n",
    "# 1. delete spaces from end of the texts\n",
    "for key, value in text_data.items():\n",
    "    text_data[key] = value.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decode import discourse_map_reverse\n",
    "from decode import lead_info, pos_info, conc_info, claim_info, evidence_info, count_info, rebuttal_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add discourse start and ending positions\n",
    "\n",
    "def get_lead_pos_cs_preds(idx, word_probs, label_idx, p_start, p_end, min_conf, min_words, offset_mapping, token_to_word):\n",
    "        \n",
    "    sample_preds = []\n",
    "\n",
    "    class_probs = word_probs[:, label_idx]\n",
    "        \n",
    "    # start index candidates\n",
    "    start_candidates = np.where(class_probs >= p_start)[0]\n",
    "    # end index candidates\n",
    "    end_candidates = np.where(class_probs >= p_end)[0]\n",
    "        \n",
    "    if (len(start_candidates)>0) and (len(end_candidates)>0):\n",
    "        start_idx = start_candidates[0]\n",
    "        end_idx = end_candidates[-1]\n",
    "        num_word = end_idx - start_idx + 1\n",
    "        confidence = class_probs[start_idx:end_idx+1].mean()\n",
    "\n",
    "        if (confidence>=min_conf) and (num_word>=min_words):\n",
    "            # format prediction\n",
    "            this_preds = [str(idx) for idx in range(start_idx, end_idx+1)]\n",
    "            this_preds = ' '.join(this_preds)\n",
    "            \n",
    "            discourse_start = offset_mapping[np.where(token_to_word == start_idx)[0][0]][0]\n",
    "            discourse_end = offset_mapping[np.where(token_to_word == end_idx)[0][-1]][1]            \n",
    "            \n",
    "            sample_preds.append([idx, discourse_map_reverse[label_idx], this_preds, discourse_start, discourse_end, confidence])\n",
    "\n",
    "    return sample_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_claim_evidence_preds(idx, word_probs, start_label, body_label, min_conf, min_words, offset_mapping, token_to_word):\n",
    "    \n",
    "    sample_preds = []\n",
    "    \n",
    "    start_probs = word_probs[:, start_label]\n",
    "    body_probs = word_probs[:, body_label]\n",
    "\n",
    "    word_preds = word_probs.argmax(1)\n",
    "    \n",
    "    num_words = len(word_preds)\n",
    "    \n",
    "    # clean word preds\n",
    "    for i in range(1, num_words-1):\n",
    "        if (word_preds[i-1] == 1 and  word_preds[i+1] == 1):\n",
    "            if word_preds[i] == 3:\n",
    "                word_preds[i] = 1\n",
    "    # clean word preds\n",
    "    for i in range(1, num_words-1):\n",
    "        if (word_preds[i-1] == 3 and  word_preds[i+1] == 3):\n",
    "            if word_preds[i] == 1:\n",
    "                word_preds[i] = 3       \n",
    "\n",
    "    start_positions = np.where(word_preds==start_label)[0]\n",
    "    \n",
    "    add_start = [i for i in range(1, num_words-1)\n",
    "             if (word_preds[i] == body_label and word_preds[i-1] != body_label and word_preds[i-1] != start_label)]\n",
    "    add_start = np.array(add_start)\n",
    "    start_positions = np.append(start_positions, add_start).astype(int)\n",
    "\n",
    "    for start_idx in start_positions:\n",
    "        end_idx = start_idx\n",
    "        \n",
    "        while (end_idx != num_words-1) and (word_preds[end_idx+1] == body_label):\n",
    "            end_idx += 1\n",
    "        \n",
    "        sample_num_word = end_idx - start_idx + 1\n",
    "        confidence = np.append(start_probs[start_idx], body_probs[start_idx+1:end_idx+1]).mean()\n",
    "        \n",
    "        if (confidence>=min_conf) and (sample_num_word>=min_words):\n",
    "            # format prediction\n",
    "            this_preds = [str(idx) for idx in range(start_idx, end_idx+1)]\n",
    "            this_preds = ' '.join(this_preds)\n",
    "            \n",
    "            discourse_start = offset_mapping[np.where(token_to_word == start_idx)[0][0]][0]\n",
    "            discourse_end = offset_mapping[np.where(token_to_word == end_idx)[0][-1]][1]            \n",
    "            \n",
    "            sample_preds.append([idx, discourse_map_reverse[body_label], this_preds, discourse_start, discourse_end, confidence])\n",
    "    \n",
    "    \n",
    "    return sample_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_reb_preds(idx, word_probs, label_idx, min_conf, min_words, offset_mapping, token_to_word):\n",
    "        \n",
    "    sample_preds = []\n",
    "    \n",
    "    class_probs = word_probs[:, label_idx]\n",
    "\n",
    "    word_preds = word_probs.argmax(1)\n",
    "    \n",
    "    num_words = len(word_preds)\n",
    "    \n",
    "    start_positions = [i for i in range(1, num_words-1)\n",
    "             if (word_preds[i] == label_idx and word_preds[i-1] != label_idx)]\n",
    "    start_positions = np.array(start_positions)\n",
    "    \n",
    "    if word_preds[0] == label_idx:\n",
    "        start_positions = np.append(0, start_positions).astype(int)\n",
    "    \n",
    "    for start_idx in start_positions:\n",
    "        end_idx = start_idx\n",
    "        \n",
    "        while (end_idx != num_words-1) and (word_preds[end_idx+1] == label_idx):\n",
    "            end_idx += 1\n",
    "        \n",
    "        sample_num_word = end_idx - start_idx + 1\n",
    "        confidence = class_probs[start_idx:end_idx+1].mean()\n",
    "        \n",
    "        if (confidence>=min_conf) and (sample_num_word>=min_words):\n",
    "            # format prediction\n",
    "            this_preds = [str(idx) for idx in range(start_idx, end_idx+1)]\n",
    "            this_preds = ' '.join(this_preds)\n",
    "            \n",
    "            discourse_start = offset_mapping[np.where(token_to_word == start_idx)[0][0]][0]\n",
    "            discourse_end = offset_mapping[np.where(token_to_word == end_idx)[0][-1]][1]            \n",
    "            \n",
    "            sample_preds.append([idx, discourse_map_reverse[label_idx], this_preds, discourse_start, discourse_end, confidence])\n",
    "    \n",
    "    \n",
    "    return sample_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_predictions(idx, word_probs, offset_mapping, token_to_word):\n",
    "    \n",
    "    preds_decoded = []\n",
    "    \n",
    "    # 1. Lead\n",
    "    preds_decoded += get_lead_pos_cs_preds(idx, word_probs, 7, lead_info['p_start'], lead_info['p_end'], lead_info['min_conf'], lead_info['min_words'],\n",
    "                                          offset_mapping, token_to_word)\n",
    "        \n",
    "    # 2. Position\n",
    "    preds_decoded += get_lead_pos_cs_preds(idx, word_probs, 5, pos_info['p_start'], pos_info['p_end'], pos_info['min_conf'], pos_info['min_words'],\n",
    "                                          offset_mapping, token_to_word)    \n",
    "        \n",
    "    # 3. Concluding Statement\n",
    "    preds_decoded += get_lead_pos_cs_preds(idx, word_probs, 6, conc_info['p_start'], conc_info['p_end'], conc_info['min_conf'], conc_info['min_words'],\n",
    "                                          offset_mapping, token_to_word)\n",
    "    \n",
    "    # 4. Claim\n",
    "    preds_decoded += get_claim_evidence_preds(idx, word_probs, 2, 1, claim_info['min_conf'], claim_info['min_words'],\n",
    "                                             offset_mapping, token_to_word)\n",
    "    \n",
    "    # 5. Evidence\n",
    "    preds_decoded += get_claim_evidence_preds(idx, word_probs, 4, 3, evidence_info['min_conf'], evidence_info['min_words'],\n",
    "                                             offset_mapping, token_to_word)\n",
    "    \n",
    "    # 6. Counterclaim\n",
    "    preds_decoded += get_count_reb_preds(idx, word_probs, 8, count_info['min_conf'], count_info['min_words'],\n",
    "                                        offset_mapping, token_to_word)\n",
    "\n",
    "    # 7. Rebuttal\n",
    "    preds_decoded += get_count_reb_preds(idx, word_probs, 9, rebuttal_info['min_conf'], rebuttal_info['min_words'],\n",
    "                                        offset_mapping, token_to_word)\n",
    "    \n",
    "    return preds_decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15594 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (562 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 15594/15594 [02:41<00:00, 96.80it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(131009, 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PREDICTIONS FORMATTING\n",
    "\n",
    "oof_preds = []\n",
    "\n",
    "for idx, word_probs in tqdm(word_probs_all.items()):\n",
    "    \n",
    "    # 1. GET INPUTS\n",
    "    text = text_data[idx]\n",
    "    inputs = tokenizer(text,\n",
    "                       add_special_tokens=True,\n",
    "                       return_offsets_mapping=True,\n",
    "                       return_length=True)    \n",
    "\n",
    "    offset_mapping = inputs['offset_mapping']\n",
    "    token_to_word = np.array(data.loc[data['id'] == idx, 'token_to_word'].item())\n",
    "    \n",
    "    sample_formated = decode_predictions(idx, word_probs, offset_mapping, token_to_word)\n",
    "    \n",
    "    oof_preds += sample_formated\n",
    "    \n",
    "preds_df = pd.DataFrame(oof_preds, columns=['id', 'discourse_type', 'predictionstring', 'discourse_start' , 'discourse_end', 'confidence'])\n",
    "preds_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>predictionstring</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0C0E56A1FB05</td>\n",
       "      <td>Lead</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
       "      <td>0</td>\n",
       "      <td>247</td>\n",
       "      <td>0.980532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0C0E56A1FB05</td>\n",
       "      <td>Position</td>\n",
       "      <td>42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 5...</td>\n",
       "      <td>248</td>\n",
       "      <td>342</td>\n",
       "      <td>0.965980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0C0E56A1FB05</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>238 239 240 241 242 243 244 245 246 247 248 24...</td>\n",
       "      <td>1374</td>\n",
       "      <td>1580</td>\n",
       "      <td>0.988033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0C0E56A1FB05</td>\n",
       "      <td>Claim</td>\n",
       "      <td>59 60 61 62 63 64 65 66 67 68 69 70</td>\n",
       "      <td>344</td>\n",
       "      <td>413</td>\n",
       "      <td>0.833445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0C0E56A1FB05</td>\n",
       "      <td>Claim</td>\n",
       "      <td>131 132 133 134 135 136 137 138 139 140 141 14...</td>\n",
       "      <td>755</td>\n",
       "      <td>878</td>\n",
       "      <td>0.800700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id        discourse_type  \\\n",
       "0  0C0E56A1FB05                  Lead   \n",
       "1  0C0E56A1FB05              Position   \n",
       "2  0C0E56A1FB05  Concluding Statement   \n",
       "3  0C0E56A1FB05                 Claim   \n",
       "4  0C0E56A1FB05                 Claim   \n",
       "\n",
       "                                    predictionstring  discourse_start  \\\n",
       "0  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...                0   \n",
       "1  42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 5...              248   \n",
       "2  238 239 240 241 242 243 244 245 246 247 248 24...             1374   \n",
       "3                59 60 61 62 63 64 65 66 67 68 69 70              344   \n",
       "4  131 132 133 134 135 136 137 138 139 140 141 14...              755   \n",
       "\n",
       "   discourse_end  confidence  \n",
       "0            247    0.980532  \n",
       "1            342    0.965980  \n",
       "2           1580    0.988033  \n",
       "3            413    0.833445  \n",
       "4            878    0.800700  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df.to_csv('../data/oof_lf_rl_db.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
